#!/usr/bin/env bash

script_dir="$(dirname "${BASH_SOURCE[0]}")"
tmp_dir="${script_dir}/tmp"

function check_null {
  local var_name="$1"
  local var_value="${!var_name:-}"
  if [[ -z "$var_value" ]]; then
    echo "The environment variable $var_name must be set."
    exit 1
  fi
}

# Read a plugin property of type [array, string] into a Bash array. Buildkite
# exposes a string value at BUILDKITE_PLUGIN_{NAME}_{KEY}, and array values at
# BUILDKITE_PLUGIN_{NAME}_{KEY}_{IDX}.
function read_list_property {
  local prefix="BUILDKITE_PLUGIN_DYNAMODB_IMAGE_${1}"
  local property="${prefix}_0"
  result=()
  if [[ -n ${!property:-} ]]; then
    local i=0
    local property="${prefix}_${i}"
    while [[ -n ${!property:-} ]]; do
      result+=("${!property}")
      i=$((i + 1))
      property="${prefix}_${i}"
    done
  elif [[ -n ${!prefix:-} ]]; then
    result+=("${!prefix}")
  fi
  [[ ${#result[@]} -gt 0 ]] || return 1
}

# Read tables into an array
function read_tables {
  if read_list_property 'TABLES'; then
    for table in "${result[@]}"; do
      tables+=("${table}")
    done
  else
    echo "A list of tables must be provided."
    exit 1
  fi
}

# This is only used to test the read_tables function
function read_tables_with_output {
  read_tables
  echo "${tables[@]}" 
}

# Retrieves schemas for a list of tables and saves them as JSON
function retrieve_schemas {
  local tables=("$@")
  for table in "${tables[@]}"; do
    local schema_file="${tmp_dir}/${table}.json"
    local dynamo_json
    dynamo_json=$(aws dynamodb describe-table \
      --table-name "${table}" \
      --output json)
    echo "${dynamo_json}"
    echo "${dynamo_json}" > "${schema_file}"
  done
}

# Reads a describe-table JSON and converts it to a create-table JSON
function generate_create_json {
  local input_json_file="$1"
  echo $(jq '.Table | {TableName, KeySchema, AttributeDefinitions} + (try {LocalSecondaryIndexes: [ .LocalSecondaryIndexes[] | {IndexName, KeySchema, Projection} ]} // {}) + (try {GlobalSecondaryIndexes: [ .GlobalSecondaryIndexes[] | {IndexName, KeySchema, Projection} ]} // {}) + {BillingMode: "PAY_PER_REQUEST"}' "${input_json_file}")
}

# Creates the necessary database files and saves them to the local filesystem
function create_database {
  local tables=("$@")
  local local_dynamo_port local_dynamo_container_id local_dynamo_endpoint container_port
  
  # Start dynamo locally
  local_dynamo_port=8000
  docker pull amazon/dynamodb-local:latest
  local_dynamo_container_id=$(docker run -d -p 0:"${local_dynamo_port}" amazon/dynamodb-local:latest -jar DynamoDBLocal.jar -port "${local_dynamo_port}" -sharedDb)
  sleep 5 # TODO: This gives the container a bit of time to start up, but it would be better to poll for when its up instead

  # Create the tables
  container_port=$(docker port "${local_dynamo_container_id}" "${local_dynamo_port}" | cut -d':' -f2)
  local_dynamo_endpoint=http://localhost:"${container_port}"
  for table in "${tables[@]}"; do
    local schema_file table_json
    schema_file="${tmp_dir}/${table}.json"
    table_json=$(generate_create_json "${schema_file}")
    aws dynamodb create-table --cli-input-json "${table_json}" --region "local" --endpoint "${local_dynamo_endpoint}"
  done
  aws dynamodb list-tables --region "local" --endpoint "${local_dynamo_endpoint}"
  
  # Save the database file so that we can use it in the build
  docker cp "${local_dynamo_container_id}":/home/dynamodblocal/shared-local-instance.db "${tmp_dir}"/shared-local-instance.db

  # Stop running local dynamo
  docker stop "${local_dynamo_container_id}"
}