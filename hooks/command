#!/usr/bin/env bash

set -euo pipefail

export DOCKER_CLI_EXPERIMENTAL=enabled
export AWS_PAGER=""

build="${BUILDKITE_BUILD_NUMBER:-0}"
repository="$BUILDKITE_PLUGIN_DYNAMODB_IMAGE_REPOSITORY"
tables=()
script_dir="$(dirname "${BASH_SOURCE[0]}")"
tmp_dir="${script_dir}/tmp"
mkdir -p $tmp_dir

# read a plugin property of type [array, string] into a Bash array. Buildkite
# exposes a string value at BUILDKITE_PLUGIN_{NAME}_{KEY}, and array values at
# BUILDKITE_PLUGIN_{NAME}_{KEY}_{IDX}.
function read_list_property {
  local prefix="BUILDKITE_PLUGIN_DYNAMODB_IMAGE_${1}"
  local property="${prefix}_0"

  result=()

  if [[ -n ${!property:-} ]]; then
    local i=0
    local property="${prefix}_${i}"

    while [[ -n ${!property:-} ]]; do
      result+=("${!property}")

      i=$((i + 1))
      property="${prefix}_${i}"
    done
  elif [[ -n ${!prefix:-} ]]; then
    result+=("${!prefix}")
  fi

  [[ ${#result[@]} -gt 0 ]] || return 1
}

# Read tables into an array
function read_tables {
  if read_list_property 'TABLES'; then
    for table in "${result[@]}"; do
      tables+=("${table}")
    done
  else
    echo "A list of tables must be provided."
  fi
}

# Retrieves schemas and saves them as JSON
function retrieve_schemas {
  for table in "${tables[@]}"; do
    local schema_file="${tmp_dir}/${table}.json"
    aws dynamodb describe-table \
      --table-name "${table}" \
      --output json \
      >"${schema_file}"
  done
}

# Pulls local DynamoDB and runs it on port 8000
function start_local_dynamo {
  docker pull amazon/dynamodb-local:latest
  docker run -d -p 8000:8000 --name dynamo-local amazon/dynamodb-local:latest -jar DynamoDBLocal.jar -port 8000 -sharedDb
  sleep 5
}

# Saves the database file so that we can use it in the build
function save_database {
  docker cp dynamo-local:/home/dynamodblocal/shared-local-instance.db $tmp_dir/shared-local-instance.db
}

# Stop running local dynamo
function stop_local_dynamo {
  docker stop dynamo-local
}

# Create the tables
function create_tables {
  local local_dynamo_endpoint="http://localhost:8000"
  for table in "${tables[@]}"; do
    local schema_file="${tmp_dir}/${table}.json"
    local attributes=$(cat "${schema_file}" | jq '.["Table"]."AttributeDefinitions"')
    local key_schema=$(cat "${schema_file}" | jq '.["Table"]."KeySchema"')
    local gsis=$(cat "${schema_file}" | jq '[.["Table"]."GlobalSecondaryIndexes"[] | {Projection: .Projection, IndexName: .IndexName, KeySchema: .KeySchema }]')
    aws dynamodb create-table \
      --table-name "${table}" \
      --attribute-definitions "${attributes}" \
      --key-schema "${key_schema}" \
      --global-secondary-indexes "${gsis}" \
      --billing-mode 'PAY_PER_REQUEST' \
      --region "local" --endpoint ${local_dynamo_endpoint}
  done
  aws dynamodb list-tables --region "local" --endpoint ${local_dynamo_endpoint}
}

# Builds the multi arch image and publishes it
function build_and_publish {
  cd $script_dir
  docker buildx create --use
  if [[ ${BUILDKITE_BRANCH:-branch} == "${BUILDKITE_PIPELINE_DEFAULT_BRANCH:-master}" ]]; then
    image="${repository}:latest"
  else
    image="${repository}:branch-${build}"
  fi
  docker buildx build --push --no-cache -t $image -f $script_dir/Dockerfile --platform linux/arm64,linux/amd64 .
  docker buildx rm
}

read_tables
echo "1. Retrieve schemas..."
retrieve_schemas
echo "2. Create database file..."
start_local_dynamo
create_tables
save_database
stop_local_dynamo
echo "3. Build and publish multi-arch images..."
build_and_publish
